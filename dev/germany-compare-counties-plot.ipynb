{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_formats = ['svg']\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import oscovida\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from oscovida import unpack_region_subregion, germany_get_region, label_from_region_subregion, get_compare_data, \\\n",
    "    align_sets_at, plot_logdiff_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oscovida.make_compare_plot_germany((None, \"LK Pinneberg\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def day0atleast(v0, series):\n",
    "    try:\n",
    "        day0 = series[series > v0].index[0]\n",
    "    except IndexError:  # means no days found for which series.values > v0\n",
    "        # print(f\"Haven't found value > {v0} is Series {series.name}\")\n",
    "        result = pd.Series(dtype=object)\n",
    "        return result\n",
    "\n",
    "    # compute timedelta\n",
    "    timedelta = series.index - day0\n",
    "    # convert to int as index\n",
    "    t = pd.to_numeric(timedelta.astype(\"timedelta64[D]\").astype(int))\n",
    "    # Assemble new series\n",
    "    result = pd.Series(index=t, data=series.values)\n",
    "    # DDD print(f\"{series.name} \", result)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_html(open(\"test.html\", \"tw\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!open test.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_sets_at(v0, df):\n",
    "    \"\"\"Accepts data frame, and aligns so that all enttries close to v0 are on the same row.\n",
    "\n",
    "    Returns new dataframe with integer index (reprenting days after v0).\n",
    "    \"\"\"\n",
    "    res = pd.DataFrame()\n",
    "\n",
    "    i = 0\n",
    "    for col in df.columns:\n",
    "        i += 1\n",
    "        # res[col] = day0for(v0, df[col])\n",
    "        series = day0atleast(v0, df[col])\n",
    "        series.name = col\n",
    "        res = pd.merge(res, series, how='outer', left_index=True, right_index=True)\n",
    "        # DDD print(f\"{series.name} \", series)\n",
    "        res.to_html(open(f'test-html-{i}.html', 'tw'))\n",
    "        \n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes, res_c, res_d = oscovida.make_compare_plot_germany(\"Hamburg\", \n",
    "                                               compare_with_local=['Baden-W端rttemberg', 'Bayern', \n",
    "                                                                   'Berlin', 'Brandenburg', 'Bremen', \n",
    "                                                                   'Hamburg', 'Hessen', 'Mecklenburg-Vorpommern', \n",
    "                                                                   'Niedersachsen', 'Nordrhein-Westfalen', \n",
    "                                                                   'Rheinland-Pfalz', 'Saarland', 'Sachsen', \n",
    "                                                                   'Sachsen-Anhalt', 'Schleswig-Holstein', \n",
    "                                                                   'Th端ringen']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes, res_c, res_d = oscovida.make_compare_plot_germany(\"Hamburg\", \n",
    "                                               compare_with_local=['Bayern', \n",
    "                                                                   'Berlin', 'Bremen', \n",
    "                                                                   'Hamburg', 'Hessen', \n",
    "                                                                   'Nordrhein-Westfalen', \n",
    "                                                                   'Sachsen-Anhalt'\n",
    "                                                                   ]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes, res_c, res_d = oscovida.make_compare_plot_germany((None, \"LK Pinneberg\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compare_data_germany(region_subregion, compare_with_local, rolling=7):\n",
    "    \"\"\"Given a region_subregion for Germany, and a list of region_subregion to compare with,\n",
    "    return two dataframes: one with cases and one with deaths\n",
    "    where\n",
    "    - each column is one country\n",
    "    - data in the column is the diff of accumulated numbers\n",
    "    - any zero values are removed for italy (data error)\n",
    "    - apply some smoothing\n",
    "\n",
    "    See unpack_region_subregion for details on region_subregion.\n",
    "    \"\"\"\n",
    "    df_c = pd.DataFrame()\n",
    "    df_d = pd.DataFrame()\n",
    "\n",
    "    for reg_subreg in [region_subregion] + compare_with_local:\n",
    "\n",
    "        region, subregion = unpack_region_subregion(reg_subreg)\n",
    "        c, d = germany_get_region(state=region, landkreis=subregion)\n",
    "\n",
    "        label = label_from_region_subregion((region, subregion))\n",
    "        df_c[label] = c.diff().rolling(rolling, center=True).mean()  # cases\n",
    "        df_d[label] = d.diff().rolling(rolling, center=True).mean()  # deaths\n",
    "\n",
    "    return df_c, df_d\n",
    "\n",
    "\n",
    "def make_compare_plot_germany(region_subregion,\n",
    "                              compare_with=[], #\"China\", \"Italy\", \"Germany\"],\n",
    "                              compare_with_local =['Bayern', \n",
    "                                                   'Berlin', 'Bremen', \n",
    "                                                   'Hamburg', 'Hessen', \n",
    "                                                   'Nordrhein-Westfalen', \n",
    "                                                   'Sachsen-Anhalt'], \n",
    "    # The 'compare_with_local' subset is chosen to look sensibly on 2 May 2020.\n",
    "    #                          compare_with_local=['Baden-W端rttemberg', 'Bayern', 'Berlin',\n",
    "    #                                              'Brandenburg', 'Bremen', 'Hamburg',\n",
    "    #                                              'Hessen', 'Mecklenburg-Vorpommern', 'Niedersachsen',\n",
    "    #                                              'Nordrhein-Westfalen', 'Rheinland-Pfalz', 'Saarland',\n",
    "    #                                              'Sachsen', 'Sachsen-Anhalt', 'Schleswig-Holstein',  'Th端ringen'],\n",
    "                              v0c=10, v0d=1):\n",
    "    rolling = 7\n",
    "    region, subregion = unpack_region_subregion(region_subregion)\n",
    "    df_c1, df_d1 = get_compare_data_germany((region, subregion), compare_with_local, rolling=rolling)\n",
    "    df_c2, df_d2 = get_compare_data(compare_with, rolling=rolling)\n",
    "    # DDD df_c1 okay here as r1\n",
    "\n",
    "    # need to get index into same timezone before merging\n",
    "    df_d1.set_index(df_d1.index.tz_localize(None), inplace=True)\n",
    "    df_c1.set_index(df_c1.index.tz_localize(None), inplace=True)\n",
    "    # DDD return df_c1 # okay as r15\n",
    "\n",
    "    df_c = pd.merge(df_c1, df_c2, how='outer', left_index=True, right_index=True)\n",
    "    df_d = pd.merge(df_d1, df_d2, how='outer', left_index=True, right_index=True)\n",
    "    # return df_c # okay as r17\n",
    "    \n",
    "    res_c = align_sets_at(v0c, df_c)\n",
    "    res_d = align_sets_at(v0d, df_d)\n",
    "    \n",
    "    # We get NaNs for some lines. This seems to originate in the original data set not having a value recorded\n",
    "    # for all days. \n",
    "    # For the purpose of this plot, we'll just interpolate between the last and next known values\n",
    "    # We limit the number of fills to 3 days. (Just a guess to avoid accidental filling of too many NaNs.)\n",
    "    \n",
    "    res_c = res_c.interpolate(method='linear', limit=3)\n",
    "    res_d = res_d.interpolate(method='linear', limit=3)\n",
    "    \n",
    "    # return res_c   ### broken here (r20)\n",
    "\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(10, 6))\n",
    "    ax=axes[0]\n",
    "    plot_logdiff_time(ax, res_c, f\"days since {v0c} cases\",\n",
    "                      \"daily new cases\\n(rolling 7-day mean)\",\n",
    "                      v0=v0c, highlight={res_c.columns[0]:\"C1\"}, labeloffset=0.5)\n",
    "    ax = axes[1]\n",
    "\n",
    "    res_d_0 = res_d[res_d.index >= 0]   # from \"day 0\" only\n",
    "    # if we have values in between 0.1 and 1, set the lower `y_limit` on the graph to 0.1\n",
    "    if res_d_0[(res_d_0 > 0.1) & (res_d_0 < 1)].any().any():    # there must be a more elegant check\n",
    "        y_limit = 0.1\n",
    "    else:\n",
    "        y_limit = v0d\n",
    "    plot_logdiff_time(ax, res_d, f\"days since {v0d} deaths\",\n",
    "                      \"daily new deaths\\n(rolling 7-day mean)\",\n",
    "                      v0=y_limit, highlight={res_d.columns[0]:\"C0\"},\n",
    "                      labeloffset=0.5)\n",
    "\n",
    "    # fig.tight_layout(pad=1)\n",
    "\n",
    "    title = f\"Daily cases (top) and deaths (below) for Germany: {label_from_region_subregion((region, subregion))}\"\n",
    "    axes[0].set_title(title)\n",
    "\n",
    "    return axes, res_c, res_d\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rx = make_compare_plot_germany((None, \"LK Pinneberg\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rx = make_compare_plot_germany((None, \"LK Pinneberg\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pd.Series(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"max_rows\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
